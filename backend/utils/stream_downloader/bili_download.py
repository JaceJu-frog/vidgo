import re
import hashlib
import time
import requests
import json
import os
import subprocess
from urllib.parse import quote_plus
from django.http import JsonResponse,HttpResponse,HttpResponseNotAllowed,HttpResponseNotFound,Http404,FileResponse
from django.conf import settings  # Ensure this is at the top
from tqdm import tqdm
import argparse

# **0. Utils function
# æ›¿æ¢æ ‡é¢˜ä¸­çš„ç‰¹æ®Šå­—ç¬¦ --> ç”¨äºæ–‡ä»¶å‘½åã€‚
def sanitize_filename(title: str, max_bytes: int = 200) -> str:
    """
    æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦å¹¶é™åˆ¶é•¿åº¦

    Args:
        title: åŸå§‹æ ‡é¢˜
        max_bytes: æœ€å¤§å­—èŠ‚æ•°ï¼ˆé»˜è®¤200ï¼Œä¸ºæ–‡ä»¶æ‰©å±•åå’Œåç¼€é¢„ç•™ç©ºé—´ï¼‰

    Returns:
        æ¸…ç†åçš„æ–‡ä»¶å
    """
    special_chars = r"[ |?ï¼Ÿ*:\"<>/\\&%#@!()+^~,\';.]"
    sanitized = re.sub(special_chars, "-", title)

    # é™åˆ¶å­—èŠ‚é•¿åº¦ï¼ˆè€ƒè™‘ UTF-8 ç¼–ç ï¼Œä¸­æ–‡å­—ç¬¦å¯èƒ½å  3 ä¸ªå­—èŠ‚ï¼‰
    encoded = sanitized.encode('utf-8')
    if len(encoded) > max_bytes:
        # æˆªæ–­åˆ°æŒ‡å®šå­—èŠ‚æ•°ï¼Œé¿å…æˆªæ–­ä¸­æ–‡å­—ç¬¦ä¸­é—´
        truncated = encoded[:max_bytes].decode('utf-8', errors='ignore')
        # å»é™¤å¯èƒ½è¢«æˆªæ–­çš„å°¾éƒ¨ç ´æŸå­—ç¬¦
        sanitized = truncated.rstrip('-')

    return sanitized

from functools import reduce
from hashlib import md5
import urllib.parse
import time
import requests

mixinKeyEncTab = [
    46, 47, 18, 2, 53, 8, 23, 32, 15, 50, 10, 31, 58, 3, 45, 35, 27, 43, 5, 49,
    33, 9, 42, 19, 29, 28, 14, 39, 12, 38, 41, 13, 37, 48, 7, 16, 24, 55, 40,
    61, 26, 17, 0, 1, 60, 51, 30, 4, 22, 25, 54, 21, 56, 59, 6, 63, 57, 62, 11,
    36, 20, 34, 44, 52
]

def getMixinKey(orig: str):
    'å¯¹ imgKey å’Œ subKey è¿›è¡Œå­—ç¬¦é¡ºåºæ‰“ä¹±ç¼–ç '
    return reduce(lambda s, i: s + orig[i], mixinKeyEncTab, '')[:32]

def encWbi(params: dict, img_key: str, sub_key: str):
    'ä¸ºè¯·æ±‚å‚æ•°è¿›è¡Œ wbi ç­¾å'
    mixin_key = getMixinKey(img_key + sub_key)
    curr_time = round(time.time())
    params['wts'] = curr_time                                   # æ·»åŠ  wts å­—æ®µ
    params = dict(sorted(params.items()))                       # æŒ‰ç…§ key é‡æ’å‚æ•°
    # è¿‡æ»¤ value ä¸­çš„ "!'()*" å­—ç¬¦
    params = {
        k : ''.join(filter(lambda chr: chr not in "!'()*", str(v)))
        for k, v 
        in params.items()
    }
    query = urllib.parse.urlencode(params)                      # åºåˆ—åŒ–å‚æ•°
    wbi_sign = md5((query + mixin_key).encode()).hexdigest()    # è®¡ç®— w_rid
    params['w_rid'] = wbi_sign
    return params

def getWbiKeys() -> tuple[str, str]:
    'è·å–æœ€æ–°çš„ img_key å’Œ sub_key'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',
        'Referer': 'https://www.bilibili.com/'
    }
    resp = requests.get('https://api.bilibili.com/x/web-interface/nav', headers=headers)
    resp.raise_for_status()
    json_content = resp.json()
    img_url: str = json_content['data']['wbi_img']['img_url']
    sub_url: str = json_content['data']['wbi_img']['sub_url']
    img_key = img_url.rsplit('/', 1)[1].split('.')[0]
    sub_key = sub_url.rsplit('/', 1)[1].split('.')[0]
    return img_key, sub_key

def get_encrypt_keys():
    img_key, sub_key = getWbiKeys()

    signed_params = encWbi(
        params={
            'foo': '114',
            'bar': '514',
            'baz': 1919810
        },
        img_key=img_key,
        sub_key=sub_key
    )
    query = urllib.parse.urlencode(signed_params)
    print(signed_params["wts"], signed_params["w_rid"]) # ä¸¤ä¸ªå…³é”®å‚æ•°
    wts,w_rid=signed_params["wts"], signed_params["w_rid"]
    return wts,w_rid

# **2. è§†é¢‘åŸºæœ¬ä¿¡æ¯**
# è§£æ URLï¼Œåˆ¤æ–­ BV/AV å·åŠ Pï¼ˆè§†é¢‘çš„ç¬¬Nä¸ªåˆ†Pï¼‰

def extract_av_bv_p(url: str) -> tuple:
    bvid = avid = p = None
    bv_match = re.search(r"(BV[0-9A-Za-z]+)", url)
    av_match = re.search(r"(av\d+)", url)
    p_match = re.search(r"[?&]p=(\d+)", url)
    if bv_match:
        bvid = bv_match.group(1)
        print(f"bvid: {bvid}")
    if av_match:
        avid = av_match.group(1)
        print(f"avid: {avid}")
    if p_match:
        p = p_match.group(1)
        print(f"p: {p}")
    return bvid, avid, p

# è·å–è§†é¢‘çš„ CID åˆ—è¡¨ï¼ˆå¦‚æœæœ‰åˆ†Pä¼šè¿”å›åˆ—è¡¨ï¼‰
def get_cid(bvid: str = None, avid: str = None) -> tuple:
    info_url = "https://api.bilibili.com/x/player/pagelist"
    headers = {
        'Referer': 'https://www.bilibili.com',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
    }
    if not bvid and not avid:
        raise ValueError("Either bvid or avid must be provided.")
    params = {'bvid': bvid} if bvid else {'aid': avid}
    resp = requests.get(info_url, headers=headers, params=params)
    j = resp.json()
    cids = [item['cid'] for item in j['data']]
    data = j['data']
    return cids, data

# è·å–è§†é¢‘é¢„è§ˆå›¾é“¾æ¥ï¼Œæ ‡é¢˜ï¼Œä½œè€…ç­‰åŸºæœ¬ä¿¡æ¯
def get_video_info(bvid: str = None, avid: str = None) -> dict:
    if bvid:
        url = f"https://api.bilibili.com/x/web-interface/wbi/view?bvid={bvid}"
    elif avid:
        url = f"https://api.bilibili.com/x/web-interface/wbi/view?aid={avid}"
    else:
        raise ValueError("Either bvid or avid must be provided.")
    headers = {
        'Referer': 'https://www.bilibili.com',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
    }
    resp = requests.get(url, headers=headers)
    resp.raise_for_status()
    data = resp.json()['data']
    with open('miaowu.txt', 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)   # â‘  obj â‘¡ fp
    pic_url = data['pic']
    title = data['title']
    duration = data['duration']
    owner = data['owner']["name"]

    if not bvid:
        bvid = data['bvid']
    return {'pic_url': pic_url,'owner':owner,'duration':duration, 'title': title,'bvid': bvid}

# ä¿å­˜ JSON åˆ°æ–‡ä»¶

def save_json_to_file(json_string: str, file_path: str):
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(json_string)

# è·å– 1080p è§†é¢‘åŸé“¾æ¥ JSON
import http.client
def get_video_url(bvid: str, cid: int, sessdata: str) -> dict:
    """
    Retrieves the playurl JSON for the given bvid and cid.
    Falls back to http.client if requests gets a 412 error.
    """
    quality_num=80
    wts,w_rid=get_encrypt_keys()  # è·å–æœ€æ–°çš„ wts å’Œ w_rid
    print(wts,w_rid)
    path = (
        f"/x/player/wbi/playurl?bvid={bvid}&cid={cid}&qn=0&fnval={quality_num}&fnver=0&fourk=1&gaia_source=view-card&wts={wts}&w_rid={w_rid}" # æ–°çš„api
        # f"/x/player/playurl?bvid={bvid}&cid={cid}&qn=0&fnval={quality_num}&fnver=0&fourk=1" # æ—§çš„api.
    )
    headers = {'Cookie': f"SESSDATA={sessdata}"}
    try:
        # Attempt with requests
        url = f"https://api.bilibili.com{path}"
        resp = requests.get(url, headers=headers)
        resp.raise_for_status()
        json_data = resp.json()
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 412:
            # Fallback to http.client for protected endpoint
            conn = http.client.HTTPSConnection("api.bilibili.com")
            conn.request("GET", path, headers=headers)
            res = conn.getresponse()
            raw = res.read().decode('utf-8')
            json_data = json.loads(raw)
        else:
            raise
    # Save for debugging
    save_json_to_file(json.dumps(json_data, indent=4), "videos_url.json")
    return json_data

# è§£ææµåª’ä½“é“¾æ¥

def parse_video_url(raw_vid_json: dict) -> dict:
    data = raw_vid_json.get('data', {}).get('dash', {})
    videos = data.get('video', [])
    audios = data.get('audio', [])
    # ä¼˜å…ˆé€‰æ‹©1080P (id=80)
    video_item = next((v for v in videos if v.get('id') == 80), None)
    # å¦‚æœ1080Pä¸å­˜åœ¨ï¼Œåˆ™å°è¯•720P (id=48)
    if not video_item:
        video_item = next((v for v in videos if v.get('id') == 64), None)
        if video_item:
            print("720P (id=48) available, using this stream.")
    # å¦åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨åˆ†è¾¨ç‡
    if not video_item and videos:
        video_item = videos[0]
        print("Neither 1080p nor 720p (id=64) found, using first available resolution.")
    audio_item = next((a for a in audios if a.get('id') == 30280), None)
    if not audio_item and audios:
        audio_item = audios[0]
        print("80åˆ†è¾¨ç‡çš„éŸ³é¢‘æœªæ‰¾åˆ°ï¼Œä½¿ç”¨å…¶ä»–åˆ†è¾¨ç‡ã€‚")
    result = {}
    if video_item:
        result['vidBaseUrl'] = video_item.get('baseUrl')
        result['vidBackUrl'] = video_item.get('backupUrl', [None])[0]
    if audio_item:
        result['audBaseUrl'] = audio_item.get('baseUrl')
        result['audBackUrl'] = audio_item.get('backupUrl', [None])[0]
    return result

# ä¸‹è½½æ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦

def download_file_with_progress(url: str, filename: str, progress_callback=None):
    """
    ä¸‹è½½æ–‡ä»¶å¹¶å®æ—¶æŠ¥å‘Šè¿›åº¦

    Args:
        url: ä¸‹è½½URL
        filename: ä¿å­˜æ–‡ä»¶å
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•° callback(percent: int)ï¼ŒèŒƒå›´ 0-100
    """
    headers = {
        'Referer': 'https://www.bilibili.com',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
    }
    resp = requests.get(url, headers=headers, stream=True)
    total = int(resp.headers.get('content-length', 0))
    downloaded = 0
    chunk_size = 512 * 1024  # ä¼˜åŒ–ï¼šä»1KBæå‡åˆ°512KBï¼ˆå‚è€ƒGILåˆ†æï¼‰

    with open(filename, 'wb') as f:
        for chunk in tqdm(resp.iter_content(chunk_size=chunk_size),
                          total=total // chunk_size,
                          unit='KB',
                          desc=f"Downloading {os.path.basename(filename)}"):
            if chunk:
                f.write(chunk)
                downloaded += len(chunk)

                # ğŸ†• å›è°ƒè¿›åº¦ç™¾åˆ†æ¯”
                if progress_callback and total > 0:
                    percent = int((downloaded / total) * 100)
                    progress_callback(percent)

# åˆå¹¶éŸ³è§†é¢‘æ–‡ä»¶

def merge_audio_video(audio_file: str, video_file: str, output_file: str, progress_callback=None):
    """
    ä½¿ç”¨FFmpegåˆå¹¶éŸ³è§†é¢‘ï¼Œæ”¯æŒçœŸå®è¿›åº¦å›è°ƒ

    Args:
        audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        video_file: è§†é¢‘æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•° callback(percent: int)ï¼ŒèŒƒå›´ 0-100
    """
    cmd = [
        'ffmpeg', '-y', '-i', video_file, '-i', audio_file,
        '-c:v', 'copy', '-c:a', 'aac', '-strict', 'experimental',
        '-progress', 'pipe:1',  # è¾“å‡ºè¿›åº¦åˆ°stdout
        output_file
    ]

    if not progress_callback:
        # æ— éœ€è¿›åº¦å›è°ƒï¼Œç›´æ¥è¿è¡Œ
        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
        return

    # ğŸ†• è·å–è§†é¢‘æ€»æ—¶é•¿ï¼ˆç”¨äºè®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”ï¼‰
    import json
    probe_cmd = [
        'ffprobe', '-v', 'error',
        '-show_entries', 'format=duration',
        '-of', 'json',
        video_file
    ]
    probe_result = subprocess.run(probe_cmd, capture_output=True, text=True)
    duration = 0.0
    try:
        probe_data = json.loads(probe_result.stdout)
        duration = float(probe_data['format']['duration'])
    except (json.JSONDecodeError, KeyError, ValueError):
        duration = 0.0

    # ğŸ†• å¯åŠ¨FFmpegè¿›ç¨‹å¹¶è§£æè¿›åº¦
    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, text=True)

    for line in process.stdout:
        line = line.strip()
        # FFmpegè¿›åº¦è¾“å‡ºæ ¼å¼ï¼šout_time_ms=12345678
        if line.startswith('out_time_ms='):
            try:
                time_ms = int(line.split('=')[1])
                current_time = time_ms / 1_000_000  # å¾®ç§’è½¬ç§’
                if duration > 0:
                    percent = min(int((current_time / duration) * 100), 99)
                    progress_callback(percent)
            except (ValueError, IndexError):
                pass

    process.wait()
    if process.returncode != 0:
        raise subprocess.CalledProcessError(process.returncode, cmd)

    progress_callback(100)  # å®Œæˆæ—¶ç¡®ä¿100%

from pathlib import Path           # æ¯” os.path æ›´å¥½ç”¨
WORK_DIR = Path(settings.BASE_DIR, "work_dir")   # â€¦/<your_project>/work_dir
WORK_DIR.mkdir(exist_ok=True)
def get_direct_media_link(bvid,cid=None,title=None,idx=None,sessdata=""):
    if cid is None or title is None :
        info = get_video_info(bvid=bvid, avid="") # å¯ä»¥æœ‰ï¼Œä½†æ˜¯å‰ç«¯å¦‚æœç»™äº†çš„è¯å°±ä¸ç”¨äº†
        bvid = info['bvid']
        cid = info['cid']
        title = info['title']
    safe_title = sanitize_filename(f"{title}-{idx}")
    vid_json = get_video_url(bvid=bvid, cid=cid, sessdata=sessdata)
    urls = parse_video_url(vid_json)
    video  = WORK_DIR / f"{safe_title}_video.mp4"
    audio  = WORK_DIR / f"{safe_title}_audio.mp3"
    merged = WORK_DIR / f"{safe_title}_merged.mp4"
    return video,audio,merged,urls
    
# ä¸»å‡½æ•°
def main_bili_downloader(url: str, sessdata: str, down_list: bool = False):
    bvid, avid, p = extract_av_bv_p(url)
    cids, data = get_cid(bvid=bvid, avid=avid)
    # å¤„ç†å¤š P
    if len(data) > 1 and not down_list:
        print("Multiple videos found. Please select which to download:")
        for idx, item in enumerate(data, 1):
            part = item.get('part') or f"Part {idx}"
            dur = item.get('duration')
            print(f"{idx}. {part} ({dur}s)")
        answer = input("Enter numbers (comma-separated) or 'full': ").strip().lower()
        if answer == 'full':
            selected = list(range(len(data)))
        else:
            selected = [int(i)-1 for i in answer.split(',')]
        data = [item for idx, item in enumerate(data) if idx in selected]
    # ä¸‹è½½æ¯ä¸ªåˆ†P
    for idx, item in enumerate(data, 1):
        info = get_video_info(bvid=bvid, avid=avid)
        bvid = info['bvid']
        cid = item['cid']
        title = info['title']
        safe_title = sanitize_filename(f"{title}-{idx}")
        vid_json = get_video_url(bvid=bvid, cid=cid, sessdata=sessdata)
        urls = parse_video_url(vid_json)
        video_file = f"work_dir/{safe_title}_video.mp4"
        audio_file = f"work_dir/{safe_title}_audio.mp3"
        output_file = f"work_dir/{safe_title}_merged.mp4"
        download_file_with_progress(urls['vidBaseUrl'], video_file)
        download_file_with_progress(urls['audBaseUrl'], audio_file)
        merge_audio_video(audio_file, video_file, output_file)
        # æ¸…ç†ä¸­é—´æ–‡ä»¶
        # for fpath in [video_file, audio_file]:
        for fpath in [video_file]:
            try:
                os.remove(fpath)
            except OSError:
                pass

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Download Bilibili videos with audio merge')
    parser.add_argument('--url', default="https://www.bilibili.com/video/BV19e4y1q7JJ?spm_id_from=333.788.recommend_more_video.-1&vd_source=3d7594eace7bea23a96123faecc64e41", help='BV/AV URL')
    parser.add_argument('--sessdata',default="bd6c83c2%2C1768619794%2Ce2a7c%2A71CjBZZspc9z0-KH-fPDTEwRGeVY5_Rqj0FqU9saO4hRRX9crVvGBj6TS85gZLG3tWLfISVmc4WFhUTzJLMVdLVE80OThaNUdZNDZsODRUV3ZNRV9zc1NyUkZ5eVNtRHRGQ1dFSVJyUmhqNi0yTnJ6NXhEU3RvN3FWbVRsTWo4ODB4VGhiR1ZEQkJ3IIEC", help='SESSDATA cookie value')
    parser.add_argument('--down_list', action='store_true', help='Download all parts without prompt')
    args = parser.parse_args()
    main_bili_downloader(args.url, args.sessdata, args.down_list)
